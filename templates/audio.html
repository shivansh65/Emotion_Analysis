{% extends "base.html" %}
{% block title %}Emotion Detection from Audio{% endblock %}
{% block content %}
<div class="container mt-5">
    <div class="row justify-content-center">
        <div class="col-md-8 col-lg-6">
            <div class="card shadow-lg">
                <div class="card-header text-center py-4">
                    <h1 class="display-5">Emotion Detection from Audio</h1>
                    <p class="lead">Upload an audio file or record audio to detect the emotion.</p>
                </div>
                <div class="card-body p-4">
                    <form action="/audio" method="post" enctype="multipart/form-data">
                        <div class="mb-3">
                            <label for="audioFile" class="form-label">Choose an audio file</label>
                            <input type="file" class="form-control" id="audioFile" name="file" accept="audio/*" required>
                        </div>
                        <div class="d-grid">
                            <button type="submit" class="btn btn-primary btn-lg">Detect Emotion</button>
                        </div>
                    </form>
                    <div class="d-grid mt-3">
                        <button id="resetUploadBtn" class="btn btn-secondary btn-lg">Reset</button>
                    </div>
                    <hr class="my-4">
                    <div class="text-center">
                        <h5 class="mb-3">Or record audio</h5>
                        <button id="startRecordingBtn" class="btn btn-outline-dark btn-lg mb-3">Start Recording</button>
                        <button id="stopRecordingBtn" class="btn btn-outline-dark btn-lg mb-3" disabled>Stop Recording</button>
                        <audio id="audioPlayback" controls class="w-100 mt-3" style="display: none;"></audio>
                        <div class="d-grid mt-3">
                            <button id="detectRecordedEmotionBtn" class="btn btn-primary btn-lg" style="display: none;">Detect Emotion from Recorded Audio</button>
                        </div>
                        <div class="d-grid mt-3">
                            <button id="resetRecordingBtn" class="btn btn-secondary btn-lg">Reset</button>
                        </div>
                    </div>
                    {% with messages = get_flashed_messages(with_categories=true) %}
                        {% if messages %}
                            <div class="mt-4">
                                {% for category, message in messages %}
                                    <div class="alert alert-{{ category }} alert-dismissible fade show" role="alert">
                                        {{ message }}
                                        <button type="button" class="btn-close" data-bs-dismiss="alert" aria-label="Close"></button>
                                    </div>
                                {% endfor %}
                            </div>
                        {% endif %}
                    {% endwith %}
                    {% if emotion %}
                    <div class="result text-center mt-4 p-3">
                        <h3 class="mb-3">Result</h3>
                        <p class="display-6 text-primary fw-bold">{{ emotion }}</p>
                        {% if emotion in ['angry', 'stressed', 'anxious', 'sad'] %}
                        <p class="motivational-message">It's okay to feel this way. Take a deep breath and remember that you are strong and capable.</p>
                        {% endif %}
                    </div>
                    {% endif %}
                </div>
            </div>
        </div>
    </div>
</div>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.min.js"></script>
<script>
    let mediaRecorder;
    let audioChunks = [];

    document.getElementById('startRecordingBtn').addEventListener('click', async () => {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();

        mediaRecorder.addEventListener('dataavailable', event => {
            audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener('stop', () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = document.getElementById('audioPlayback');
            audio.src = audioUrl;
            audio.style.display = 'block';
            document.getElementById('detectRecordedEmotionBtn').style.display = 'block';

            // Send the recorded audio to the server for emotion detection
            document.getElementById('detectRecordedEmotionBtn').addEventListener('click', () => {
                const formData = new FormData();
                formData.append('file', audioBlob, 'recorded_audio.wav');
                fetch('/audio', {
                    method: 'POST',
                    body: formData
                })
                .then(response => response.text())
                .then(html => {
                    document.open();
                    document.write(html);
                    document.close();
                })
                .catch(error => console.error('Error:', error));
            });
        });

        document.getElementById('startRecordingBtn').disabled = true;
        document.getElementById('stopRecordingBtn').disabled = false;
    });

    document.getElementById('stopRecordingBtn').addEventListener('click', () => {
        mediaRecorder.stop();
        document.getElementById('startRecordingBtn').disabled = false;
        document.getElementById('stopRecordingBtn').disabled = true;
    });

    document.getElementById('resetUploadBtn').addEventListener('click', () => {
        document.getElementById('audioFile').value = '';
        document.getElementById('detectRecordedEmotionBtn').style.display = 'none';
        document.getElementById('audioPlayback').style.display = 'none';
        const result = document.querySelector('.result');
        if (result) {
            result.style.display = 'none';
        }
    });

    document.getElementById('resetRecordingBtn').addEventListener('click', () => {
        audioChunks = [];
        const audio = document.getElementById('audioPlayback');
        audio.src = '';
        audio.style.display = 'none';
        document.getElementById('detectRecordedEmotionBtn').style.display = 'none';
        document.getElementById('startRecordingBtn').disabled = false;
        document.getElementById('stopRecordingBtn').disabled = true;
        const result = document.querySelector('.result');
        if (result) {
            result.style.display = 'none';
        }
    });

    // Ensure the result section is hidden on reset
    document.getElementById('resetRecordingBtn').addEventListener('click', () => {
        const result = document.querySelector('.result');
        if (result) {
            result.style.display = 'none';
        }
    });

    // Ensure the result section is hidden on reset after emotion detection
    document.getElementById('detectRecordedEmotionBtn').addEventListener('click', () => {
        document.getElementById('resetRecordingBtn').addEventListener('click', () => {
            audioChunks = [];
            const audio = document.getElementById('audioPlayback');
            audio.src = '';
            audio.style.display = 'none';
            document.getElementById('detectRecordedEmotionBtn').style.display = 'none';
            document.getElementById('startRecordingBtn').disabled = false;
            document.getElementById('stopRecordingBtn').disabled = true;
            const result = document.querySelector('.result');
            if (result) {
                result.style.display = 'none';
            }
        });
    });
</script>
{% endblock %}
